# monitoring/check_data_drift.py
import pandas as pd
import numpy as np
from scipy import stats
import os
import json
from datetime import datetime

PSI_THRESHOLD = 0.2
KS_PVALUE_THRESHOLD = 0.05

def calculate_psi(expected, actual, bins=10):
    expected = np.array(expected)
    actual = np.array(actual)
    expected = (expected - expected.min()) / (expected.max() - expected.min() + 1e-8)
    actual = (actual - actual.min()) / (actual.max() - actual.min() + 1e-8)
    
    bins_edges = np.percentile(expected, np.linspace(0, 100, bins + 1))
    expected_bins = np.histogram(expected, bins=bins_edges)[0] + 1
    actual_bins = np.histogram(actual, bins=bins_edges)[0] + 1

    expected_dist = expected_bins / expected_bins.sum()
    actual_dist = actual_bins / actual_bins.sum()
    psi = np.sum((expected_dist - actual_dist) * np.log(expected_dist / actual_dist))
    return psi

def check_data_drift():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å
    ref_path = "monitoring/reference/reference_features.parquet"
    if not os.path.exists(ref_path):
        print("‚ö†Ô∏è –ù–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö —Ñ–∏—á–µ–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥—Ä–µ–π—Ñ–∞")
        return False

    ref_df = pd.read_parquet(ref_path)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ–∂–∏–µ –ª–æ–≥–∏ (–∑–∞ –≤—á–µ—Ä–∞ –∏–ª–∏ —Å–µ–≥–æ–¥–Ω—è)
    today = datetime.utcnow().strftime("%Y-%m-%d")
    yesterday = (datetime.utcnow() - pd.Timedelta(days=1)).strftime("%Y-%m-%d")

    current_df = pd.DataFrame()
    for date in [today, yesterday]:
        log_file = f"monitoring/logs/predictions_{date}.jsonl"
        if not os.path.exists(log_file):
            continue
            
        features_list = []
        with open(log_file, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    continue
                try:
                    entry = json.loads(line)
                    if isinstance(entry, dict) and entry["features"] is not None and isinstance(entry["features"], dict):
                        features_list.append(entry["features"])
                    else:
                        print(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ —Å—Ç—Ä–æ–∫–µ {line_num} —Ñ–∞–π–ª–∞ {log_file}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {line_num} —Ñ–∞–π–ª–∞ {log_file}: {e}")
                    continue

        if features_list:
            df_features = pd.DataFrame(features_list)
            current_df = pd.concat([current_df, df_features], ignore_index=True)

    if current_df.empty:
        print("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥—Ä–µ–π—Ñ–∞ —Ñ–∏—á–µ–π")
        return False

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–Ω–æ–º—É –Ω–∞–±–æ—Ä—É –∫–æ–ª–æ–Ω–æ–∫
    common_features = ref_df.columns.intersection(current_df.columns)
    if len(common_features) == 0:
        print("‚ö†Ô∏è –ù–µ—Ç –æ–±—â–∏—Ö —Ñ–∏—á–µ–π –º–µ–∂–¥—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–º –∏ —Ç–µ–∫—É—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        return False

    ref_df = ref_df[common_features]
    current_df = current_df[common_features]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é —Ñ–∏—á—É
    drift_detected = False
    results = {}

    for col in common_features:
        ref_vals = ref_df[col].dropna()
        curr_vals = current_df[col].dropna()
        if len(ref_vals) < 10 or len(curr_vals) < 10:
            continue

        # KS-—Ç–µ—Å—Ç
        _, pval = stats.ks_2samp(ref_vals, curr_vals)
        
        # PSI
        psi = calculate_psi(ref_vals, curr_vals)

        results[col] = {"psi": float(psi), "ks_pvalue": float(pval)}
        
        if psi > PSI_THRESHOLD or pval < KS_PVALUE_THRESHOLD:
            print(f"üö® –î—Ä–µ–π—Ñ –≤ —Ñ–∏—á–µ '{col}': PSI={psi:.4f}, KS p-value={pval:.4f}")
            drift_detected = True

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs("monitoring/drift_logs", exist_ok=True)
    
    # –õ–æ–≥–∏—Ä—É–µ–º
    log_entry = {
        "timestamp": datetime.utcnow().isoformat(),
        "component": "feature_drift",
        "drift_detected": bool(drift_detected),
        "details": results
    }
    with open("monitoring/drift_logs/drift_log.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

    if not drift_detected:
        print("‚úÖ –î—Ä–µ–π—Ñ —Ñ–∏—á–µ–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
    return drift_detected

if __name__ == "__main__":
    check_data_drift()